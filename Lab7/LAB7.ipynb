{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LAB7_EXAM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN6eK9LavB/50yYfW0w8eRN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJQRl5c-hE8e","executionInfo":{"status":"ok","timestamp":1611828466515,"user_tz":-60,"elapsed":623,"user":{"displayName":"Francesco Montagna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZlVwZVpoU2PM_x8Ak8PVU-Q2oPz6HZYJj-tTECw=s64","userId":"05516465888736070495"}},"outputId":"544fb382-7e87-48bf-f811-ec6758fc424d"},"source":["import os\r\n","import numpy as np\r\n","import pandas as pd\r\n","import tensorflow as tf\r\n","import tensorflow.keras as keras\r\n","import matplotlib.pyplot as plt\r\n","import random\r\n","%tensorflow_version 1.x\r\n","from collections import defaultdict"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pVITu4jshXzN"},"source":["# Linear Regression"]},{"cell_type":"markdown","metadata":{"id":"CrMRlZfVsHgf"},"source":["Documentazione GradientTape():  \r\n","https://www.tensorflow.org/api_docs/python/tf/GradientTape?version=nightly  \r\n","\r\n","* tensors created with tf.Variable are automatically watched\r\n","* I can manually watch a tensor with tape.watch(my_tensor). Questo metodo non riesco a farlo funionare. Anche usando @tf.function decorator, non riesco a farlo funzionare\r\n","* @tf.function decorator sopra train_step trasforma EagerTensor in Tensor\r\n","\r\n","In both cases, my params in order to be watched must be tensors  \r\n","  \r\n","Documentazione customize fit:\r\n","https://keras.io/guides/customizing_what_happens_in_fit/"]},{"cell_type":"code","metadata":{"id":"97VD7-cWhbIp"},"source":["class LinearRegression(keras.Model):\r\n","\r\n","  def __init__(self):\r\n","    super(LinearRegression, self).__init__(self)\r\n","    self.m = tf.Variable(\r\n","        initial_value=tf.convert_to_tensor(random.uniform(0, 1), dtype=\"float32\"),\r\n","        trainable=True\r\n","    )\r\n","    self.q = tf.Variable(\r\n","        initial_value=tf.convert_to_tensor(random.uniform(0, 1), dtype=\"float32\"),\r\n","        trainable=True\r\n","    )\r\n","\r\n","\r\n","  def compile(self, loss_fn, optimizer):\r\n","    super(LinearRegression, self).compile()\r\n","    self.loss_fn = loss_fn\r\n","    self.optimizer = optimizer\r\n","\r\n","  def __call__(self, x):\r\n","    return self.m*x + self.q\r\n","\r\n","  def train_step(self, x, y):\r\n","    \r\n","    with tf.GradientTape() as tape:\r\n","      y_pred = self(x)\r\n","      loss = self.loss_fn(y, y_pred)\r\n","\r\n","    gradients = tape.gradient(loss, [self.m, self.q])\r\n","    self.optimizer.apply_gradients(zip(gradients, [self.m, self.q]))\r\n","\r\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gf66d63_j8sL"},"source":["# Synthetic dataset\r\n","noise = np.random.normal(0, 1, size=(10,))\r\n","x = np.random.randint(0, 10, size=(10, ))\r\n","y = x + 2 + noise"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkEJ68NanKmR"},"source":["# Arguments\r\n","epochs = 100\r\n","learning_rate = 1e-1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"64kkIh9skgXM"},"source":["model = LinearRegression()\r\n","optim = keras.optimizers.Adam(learning_rate)\r\n","loss = keras.losses.MeanSquaredError()\r\n","\r\n","model.compile(loss, optim)\r\n","for epoch in range(epochs):\r\n","  loss = model.train_step(x, y)\r\n","  print(f\"Epoch {epoch} - Loss: {loss}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hPAi2g-cw6U6"},"source":["# GAN"]},{"cell_type":"markdown","metadata":{"id":"lx_2cQhwKlxN"},"source":["Some key points from tf.data.Dataset documentation:  \r\n","* *__prefetch__(buffer_size)*  \r\n","Creates a Dataset that prefetches elements from this dataset.  \r\n","Like other Dataset methods, prefetch operates on the elements of the input dataset. It has no concept of examples vs. batches. *examples.prefetch(2)* will prefetch two elements (2 examples), while *examples.batch(20).prefetch(2)* will prefetch 2 batches (2 batches, of 20 examples each).  \r\n","* *__batch__(batch_size, drop_remainder=False)*\r\n","* *shuffle(buffer_size, seed=None, reshuffle_each_iteration=None)*  \r\n","Randomly shuffles the elements of this dataset.  \r\n","This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. __For perfect shuffling__, a buffer size greater than or equal to the full size of the dataset is required.  \r\n","\r\n","Both shuffle and batch methods are **not inplace**"]},{"cell_type":"markdown","metadata":{"id":"UQCs3CcFMOqc"},"source":["## Arguments\r\n"]},{"cell_type":"code","metadata":{"id":"BhP50KdaMSJH"},"source":["LATENT_DIM = 100\r\n","BATCH_SIZE = 64\r\n","BUFFER_SIZE = 70000\r\n","EPOCHS = 30"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IuwzzMtn2DvG"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"m_uFbqFL2uOj"},"source":["load_data() returns\r\n","*Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test).*  \r\n","\r\n","**Important point**: the tuples are made of numpy array ==> I can access shape with *x_train.shape*  \r\n","I consider more safe to do *tf.shape(x_train)*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufffUelH2Fc4","executionInfo":{"status":"ok","timestamp":1611828469644,"user_tz":-60,"elapsed":869,"user":{"displayName":"Francesco Montagna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZlVwZVpoU2PM_x8Ak8PVU-Q2oPz6HZYJj-tTECw=s64","userId":"05516465888736070495"}},"outputId":"3a564a46-0f49-4871-f063-47b8760c13b2"},"source":["train_data, test_data = keras.datasets.fashion_mnist.load_data()\r\n","\r\n","# Concatenate test and train datasets\r\n","dataset = np.concatenate((train_data[0], test_data[0]), axis=0).astype('float32') / 255 # normalize data\r\n","dataset = np.expand_dims(dataset, axis=-1)\r\n","print(dataset.shape)\r\n","dataset = tf.data.Dataset.from_tensor_slices(dataset)\r\n","\r\n","dataset = dataset.batch(BATCH_SIZE).shuffle(BUFFER_SIZE).prefetch(10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(70000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QfPMn4k70C7j"},"source":["## Generator\r\n","Implementing Generator of DCGAN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scIqNaI40nHo","executionInfo":{"status":"ok","timestamp":1611830007024,"user_tz":-60,"elapsed":601,"user":{"displayName":"Francesco Montagna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZlVwZVpoU2PM_x8Ak8PVU-Q2oPz6HZYJj-tTECw=s64","userId":"05516465888736070495"}},"outputId":"ec6501e1-aad4-4f10-cbb4-54aa5ed81c6a"},"source":["inputs = keras.layers.Input(shape=(LATENT_DIM, ))  # One is the number of channels. We need to specify it only if the first layer is Conv\r\n","x = keras.layers.Dense( 4 * 4* 256)(inputs)\r\n","x = keras.layers.Reshape((4, 4, 256))(x)  # 'channel_last'\r\n","x = keras.layers.Conv2DTranspose(filters=64,\r\n","                                 kernel_size=(4, 4), \r\n","                                 strides=(1, 1),\r\n","                                 padding='valid')(x)\r\n","x = keras.layers.ReLU()(x)\r\n","x = keras.layers.Conv2DTranspose(filters=32,\r\n","                                 kernel_size=(4, 4),\r\n","                                 strides=(2, 2),\r\n","                                 padding='same')(x)\r\n","x = keras.layers.ReLU()(x)\r\n","x = keras.layers.Conv2DTranspose(filters=16,\r\n","                                 kernel_size=(4, 4),\r\n","                                 strides=(2, 2),\r\n","                                 padding='same')(x)\r\n","x = keras.layers.ReLU()(x)\r\n","outputs = keras.layers.Conv2DTranspose(filters=1,\r\n","                                 kernel_size=(1, 1),\r\n","                                 strides=(1, 1),\r\n","                                 padding='same')(x)\r\n","\r\n","# x = keras.layers.Flatten()(x)\r\n","# x = keras.layers.Dense(28 * 28 * 1)(x)\r\n","# outputs = keras.layers.Reshape((28, 28, 1))(x)\r\n","\r\n","generator = keras.Model(inputs, outputs)\r\n","generator.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_7 (InputLayer)         [(None, 100)]             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 4096)              413696    \n","_________________________________________________________________\n","reshape_3 (Reshape)          (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv2d_transpose_12 (Conv2DT (None, 7, 7, 64)          262208    \n","_________________________________________________________________\n","re_lu_9 (ReLU)               (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","conv2d_transpose_13 (Conv2DT (None, 14, 14, 32)        32800     \n","_________________________________________________________________\n","re_lu_10 (ReLU)              (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_transpose_14 (Conv2DT (None, 28, 28, 16)        8208      \n","_________________________________________________________________\n","re_lu_11 (ReLU)              (None, 28, 28, 16)        0         \n","_________________________________________________________________\n","conv2d_transpose_15 (Conv2DT (None, 28, 28, 1)         17        \n","=================================================================\n","Total params: 716,929\n","Trainable params: 716,929\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e-fc8BjMODGZ"},"source":["z = tf.random.normal(shape=(1, 100))\r\n","generated = generator(z)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXORWgYjOLUb"},"source":["discriminator_shape = tuple(generated[0].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1zrXf9CVIVz","executionInfo":{"status":"ok","timestamp":1611828474827,"user_tz":-60,"elapsed":434,"user":{"displayName":"Francesco Montagna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZlVwZVpoU2PM_x8Ak8PVU-Q2oPz6HZYJj-tTECw=s64","userId":"05516465888736070495"}},"outputId":"3f7ae769-2cc5-4280-a4b8-7ef66e9923a6"},"source":["discriminator_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28, 1)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"X-e7Q5LA0icg"},"source":["## Discriminator"]},{"cell_type":"markdown","metadata":{"id":"lLIaj8UmJDSw"},"source":["* Global max pooling ???"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfyxyKN00oCv","executionInfo":{"status":"ok","timestamp":1611830011293,"user_tz":-60,"elapsed":799,"user":{"displayName":"Francesco Montagna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZlVwZVpoU2PM_x8Ak8PVU-Q2oPz6HZYJj-tTECw=s64","userId":"05516465888736070495"}},"outputId":"9d4afd2c-6860-4a4c-c947-13e1492c9151"},"source":["discriminator = tf.keras.Sequential(\r\n","    [                                     \r\n","    tf.keras.layers.Input(shape=discriminator_shape),\r\n","    tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(2,2), padding='same'),\r\n","    tf.keras.layers.LeakyReLU(alpha=0.2),\r\n","    tf.keras.layers.Conv2D(filters=128, kernel_size=(2,2), strides=(2,2), padding='same'),\r\n","    tf.keras.layers.LeakyReLU(alpha=0.2),\r\n","    tf.keras.layers.Conv2D(filters=256, kernel_size=(2,2), strides=(2,2), padding='same'),\r\n","    tf.keras.layers.GlobalMaxPooling2D(),\r\n","    tf.keras.layers.Dense(1, activation = 'sigmoid')\r\n","    ],\r\n","  \r\n","    name=\"discriminator\"\r\n",")\r\n","\r\n","discriminator.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"discriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_9 (Conv2D)            (None, 14, 14, 64)        1088      \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 7, 7, 128)         32896     \n","_________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)    (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 4, 4, 256)         131328    \n","_________________________________________________________________\n","global_max_pooling2d_3 (Glob (None, 256)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 165,569\n","Trainable params: 165,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B6f0m__jMzbv"},"source":["## Custom Callbacks\r\n","Reference documentation:  \r\n","https://keras.io/guides/writing_your_own_callbacks/"]},{"cell_type":"code","metadata":{"id":"wfpeKsCoMzHt"},"source":["class GANMonitor(tf.keras.callbacks.Callback):\r\n","    def __init__(self, num_img=2, latent_dim=LATENT_DIM, root='images'):\r\n","        super(GANMonitor, self).__init__()\r\n","        self.num_img = num_img\r\n","        self.latent_dim = latent_dim\r\n","        self.root = root\r\n","\r\n","        if not os.path.exists(root):\r\n","          os.mkdir(root)\r\n","\r\n","    def on_epoch_end(self, epoch, logs=None):\r\n","        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\r\n","        generated_images = self.model.generator(random_latent_vectors)\r\n","        generated_images *= 255 # Denormalize\r\n","        generated_images.numpy()\r\n","        for i in range(self.num_img):\r\n","            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\r\n","            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amxcL8nXOLaA"},"source":["def schedule(epoch, lr):\r\n","  epochs = [25]\r\n","  if epoch in epochs:\r\n","    return lr*0.1\r\n","  \r\n","  return lr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r1TnpGpt0kqs"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"zOiuDDLKJJEa"},"source":["Nota importante:\r\n","Se come loss uso una string invece che una *keras.losses.LossClass*\r\n","allora devo poi usare *self.compiled_loss* invece che *self.loss* in train_step\r\n","\r\n","\r\n","__Nota Importante__  \r\n","Se uno aggiunge 0.05 random noise alle labels, le porta fuori dal range 0, 1. In particolare, nel secondo termina della loss, se la label originaria era 1, adesso è portata fuori dal range 1: (1- '>1') < 1 ==> introduco un termine negativo nella loss, che può diventare negativa.   \r\n","La domanda ssarebbe: allora perché ce lo infilano dentro? Aiuta la convergenza e tanto basta, anche se da' una loss negativa?"]},{"cell_type":"code","metadata":{"id":"6hkulQdlw9fx"},"source":["class GAN(keras.Model):\r\n","  def __init__(self, generator, discriminator, latent_dim):\r\n","    super(GAN, self).__init__()\r\n","    self.generator = generator\r\n","    self.discriminator = discriminator\r\n","    self.latent_dim = latent_dim\r\n","\r\n","\r\n","  def compile(self, d_optim, g_optim, loss_fn):\r\n","    super(GAN, self).compile()\r\n","    self.d_optim = d_optim\r\n","    self.g_optim = g_optim\r\n","    self.loss_fn = loss_fn\r\n","    \r\n","\r\n","  def train_step(self, real_images):\r\n","    if isinstance(real_images, tuple):\r\n","      real_images = real_images[0]\r\n","    batch_size = tf.shape(real_images)[0]\r\n","\r\n","    # 1. Train the discriminator passing both fake and real images\r\n","\r\n","    # Generate images\r\n","    z = tf.random.normal(shape=(batch_size, self.latent_dim))\r\n","    generated = self.generator(z)\r\n","\r\n","    # Concatenate real and fake images\r\n","    batch = tf.concat([generated, real_images], axis=0)\r\n","\r\n","    # Define labels\r\n","    labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\r\n","    # labels += 0.05 * tf.random.uniform(tf.shape(labels))  # add random noise to the labels - important trick!\r\n","\r\n","    with tf.GradientTape() as tape:\r\n","      preds = self.discriminator(batch)\r\n","      d_loss = self.loss_fn(labels, preds)\r\n","\r\n","    gradients = tape.gradient(d_loss, self.discriminator.trainable_weights)\r\n","    self.d_optim.apply_gradients(zip(gradients, self.discriminator.trainable_weights))\r\n","\r\n","    # 2. Train the generator to trick the discriminator\r\n","\r\n","    # Labels to trick: mark everything as real\r\n","    # In this way, I will have low loss if discriminator thinks generated images are real,\r\n","    # and viceversa update only if discriminator understand the images are false\r\n","    misleading_labels = tf.zeros((batch_size, 1))\r\n","\r\n","    with tf.GradientTape() as tape:\r\n","      \r\n","      z = tf.random.normal(shape=(batch_size, self.latent_dim))\r\n","      generated = self.generator(z)\r\n","      preds = self.discriminator(generated)\r\n","      g_loss = self.loss_fn(misleading_labels, preds)\r\n","\r\n","\r\n","    gradients = tape.gradient(g_loss, self.generator.trainable_weights)\r\n","    self.g_optim.apply_gradients(zip(gradients, self.generator.trainable_weights))\r\n","\r\n","    return {'d_loss': d_loss, 'g_loss': g_loss}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2jdZ7mHgPS_b"},"source":["From the documentation:  \r\n","*Do not specify the batch_size if your data is in the form of datasets, generators, or keras.utils.Sequence instances (since they generate batches)*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfPYh98kKwe-","executionInfo":{"status":"ok","timestamp":1611830493318,"user_tz":-60,"elapsed":271107,"user":{"displayName":"Francesco Montagna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZlVwZVpoU2PM_x8Ak8PVU-Q2oPz6HZYJj-tTECw=s64","userId":"05516465888736070495"}},"outputId":"ea799906-c466-4819-dae7-9a5a1d80b46c"},"source":["gan = GAN(generator, discriminator, LATENT_DIM)\r\n","\r\n","d_optim = keras.optimizers.Adam(learning_rate=0.0003)\r\n","g_optim = keras.optimizers.Adam(learning_rate=0.0003)\r\n","loss_fn = tf.keras.losses.BinaryCrossentropy()\r\n","\r\n","gan.compile(d_optim, g_optim, loss_fn)\r\n","gan.fit(dataset, epochs=EPOCHS,\r\n","        callbacks = [GANMonitor(num_img=2, latent_dim=LATENT_DIM),\r\n","                     keras.callbacks.LearningRateScheduler(schedule)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","1094/1094 [==============================] - 10s 8ms/step - d_loss: 0.4116 - g_loss: 1.6284\n","Epoch 2/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.4046 - g_loss: 1.6680\n","Epoch 3/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3976 - g_loss: 1.6704\n","Epoch 4/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3923 - g_loss: 1.7332\n","Epoch 5/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3849 - g_loss: 1.7594\n","Epoch 6/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3725 - g_loss: 1.8198\n","Epoch 7/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3714 - g_loss: 1.8399\n","Epoch 8/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3655 - g_loss: 1.8289\n","Epoch 9/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3672 - g_loss: 1.8216\n","Epoch 10/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3653 - g_loss: 1.8556\n","Epoch 11/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3647 - g_loss: 1.8105\n","Epoch 12/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3629 - g_loss: 1.8433\n","Epoch 13/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3574 - g_loss: 1.8819\n","Epoch 14/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3552 - g_loss: 1.8751\n","Epoch 15/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3565 - g_loss: 1.8826\n","Epoch 16/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3550 - g_loss: 1.8958\n","Epoch 17/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3457 - g_loss: 1.8995\n","Epoch 18/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3424 - g_loss: 1.9819\n","Epoch 19/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3417 - g_loss: 1.9341\n","Epoch 20/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3394 - g_loss: 1.9652\n","Epoch 21/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3373 - g_loss: 1.9825\n","Epoch 22/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3324 - g_loss: 2.0352\n","Epoch 23/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3285 - g_loss: 2.0254\n","Epoch 24/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3333 - g_loss: 2.0365\n","Epoch 25/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3265 - g_loss: 2.0586\n","Epoch 26/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3181 - g_loss: 2.1136\n","Epoch 27/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3249 - g_loss: 2.0785\n","Epoch 28/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3199 - g_loss: 2.1144\n","Epoch 29/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3188 - g_loss: 2.1344\n","Epoch 30/30\n","1094/1094 [==============================] - 9s 8ms/step - d_loss: 0.3179 - g_loss: 2.1255\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc8ae036ba8>"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"0dta0JQIcXvj"},"source":["!zip -r images.zip images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQ-xWwYaeEEu"},"source":["!rm -r images"],"execution_count":null,"outputs":[]}]}